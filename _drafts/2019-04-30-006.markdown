---
layout: post
title:  "神经网络中的batch，epoch和iteration"
date:   2019-04-30 15:23:00 +0530
categories: ["work"]
author: "Stan7"
---

### BATCH
在不能将数据一次性通过神经网络的时候，就需要将数据集分成几个 batch。
Batch size：一个 batch 中的样本总数。
相对于正常数据集，如果Batch size过小，训练数据就会非常难收敛，从而导致underfitting。 
增大Batch_Size，相对处理速度加快，同时所需内存容量增加（epoch的次数需要增加以达到最好结果）。 
因此，Batchsize 的正确选择是为了在内存效率和内存容量之间寻找最佳平衡。

### EPOCH
当一个完整的数据集通过了神经网络一次并且返回了一次，这个过程称为一个 epoch。
当一个 epoch 对于计算机而言太庞大的时候，就需要把它分成多个小块。

### ITERATION
迭代是 batch 需要完成一个 epoch 的次数。在一个 epoch 中，batch 数等于迭代数。
比如对于一个有 2000 个训练样本的数据集。将 2000 个样本分成大小为 500 的 batch，那么完成一个 epoch 需要 4 个 iteration。